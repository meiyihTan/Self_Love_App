{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OneVsRest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandontan99/Self_Love_App/blob/master/OneVsRest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlgtI9xDDjFX",
        "outputId": "f15edfb7-f1a2-47e9-cf5d-ccd936b1c9b5"
      },
      "source": [
        "!git clone https://github.com/brandontan99/Self_Love_App.git\n",
        "%cd Self_Love_App"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Self_Love_App'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 196 (delta 109), reused 50 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (196/196), 1.88 MiB | 9.26 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "/content/Self_Love_App\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3rWfMcSDju9"
      },
      "source": [
        "import sys \n",
        "sys.path.append(\"./preprocessing\")\n",
        "sys.path.append(\"./utils\")\n",
        "from data_cleaning import *\n",
        "from Data_Normalization import *\n",
        "from feature_selection import *\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statistics\n",
        "import joblib\n",
        "from copy import deepcopy\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVeyyQKnBO2Z",
        "outputId": "10ae1fc0-f09e-4ce8-ae22-59a844e64c45"
      },
      "source": [
        "    #Feature selection\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    from sklearn.feature_selection import chi2, SelectKBest\n",
        "    # to do the chi2 analysis\n",
        "    df = pd.read_csv(\"WID3006 ML Questionnaire.csv\")\n",
        "    df = data_cleaning(df)\n",
        "    # label encoding is used instead of one-hot encoding because one-hot encoding will create many features for one question\n",
        "    # but label encoding is able to perform chi-square test between a single question as a whole and the hobby  \n",
        "    x_df, y_df = label_encoding(df)\n",
        "    # only evaluate on train data to prevent data leakage\n",
        "    x_train_label_encoded, _, y_train, _ = train_test_split(x_df.to_numpy(), y_df.to_numpy(), test_size=0.2, random_state=1)\n",
        "    chi2_result = chi2_analysis(x_train_label_encoded, x_df, y_train)\n",
        "\n",
        "    # to do Recursive Feature Elimination(rfe) feature selection\n",
        "    df = pd.read_csv(\"WID3006 ML Questionnaire.csv\")\n",
        "    df = data_cleaning(df)\n",
        "    df = data_encoding(df)\n",
        "    df_norm = data_normalization(df)\n",
        "    x = df_norm.iloc[:, :64]\n",
        "    y = df_norm.iloc[:, 64:]\n",
        "    x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=0.2, random_state=1)\n",
        "    rfe_result = rfe_cv(x_train, y_train, x.columns, y.columns, LogisticRegression())\n",
        "\n",
        "    # to pick the selected best questions as features\n",
        "    # Eg: choose the best 13 features as below\n",
        "    df = pd.read_csv(\"WID3006 ML Questionnaire.csv\")\n",
        "    df = data_cleaning(df)\n",
        "    df = data_encoding(df)\n",
        "    df_norm = data_normalization(df)\n",
        "    # choose either chi2 or rfe \n",
        "    best_k_features = select_best_k_features(chi2_result, k=13) # choose chi2_result \n",
        "    best_k_features = select_best_k_features(rfe_result, k=13) # choose rfe_analysis\n",
        "    x = filter_features(best_k_features, df_norm)\n",
        "    x_train, x_test,y_train,y_test = train_test_split(x,y, random_state=1, test_size=0.25, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hobby: Sports and Outdoors\n",
            "Best number of features: 11\n",
            "Score: 0.6797849462365592\n",
            "1 Gender: _Male\n",
            "21 Choose a pet which you prefer to keep._Horse\n",
            "25 Choose a pet which you prefer to keep._Tortoise\n",
            "40 What is your favorite color?_Blue\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "55 Would you prefer to engage your brain more than your body?\n",
            "57 Are you a perfectionist?\n",
            "58 Are you a trusting person?\n",
            "59 Do you have lot of patience?\n",
            "64 How confident are you in your own abilities?\n",
            "\n",
            "Hobby: Games\n",
            "Best number of features: 10\n",
            "Score: 0.5944086021505377\n",
            "1 Gender: _Male\n",
            "4 What is your current occupation?_University student\n",
            "11 I prefer to spend my money on...._The latest fashion\n",
            "22 Choose a pet which you prefer to keep._I'm not a pet person\n",
            "31 What do you worry more about the most?_Money\n",
            "33 What do you worry more about the most?_Your family and friends\n",
            "35 When you retire, you'd like to live..._Exactly where I live now\n",
            "42 What is your favorite color?_Purple\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "61 Do you like to sit in front of a computer for long hours?\n",
            "\n",
            "Hobby: Spiritual and Mental\n",
            "Best number of features: 18\n",
            "Score: 0.6270967741935484\n",
            "1 Gender: _Male\n",
            "6 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "15 How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar\n",
            "17 Choose a pet which you prefer to keep._Cat\n",
            "24 Choose a pet which you prefer to keep._Snake\n",
            "30 Would you rather visit the future or the past?_The past\n",
            "31 What do you worry more about the most?_Money\n",
            "36 When you retire, you'd like to live..._In a hectic big city\n",
            "37 When you retire, you'd like to live..._In a small town\n",
            "43 What is your favorite color?_Red\n",
            "44 What is your favorite color?_White\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "62 Do you enjoy making others happy?\n",
            "63 Can you understand others' perspectives and feelings?\n",
            "\n",
            "Hobby: Performing Arts\n",
            "Best number of features: 12\n",
            "Score: 0.6348387096774193\n",
            "1 Gender: _Male\n",
            "4 What is your current occupation?_University student\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "11 I prefer to spend my money on...._The latest fashion\n",
            "14 How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud\n",
            "31 What do you worry more about the most?_Money\n",
            "33 What do you worry more about the most?_Your family and friends\n",
            "35 When you retire, you'd like to live..._Exactly where I live now\n",
            "41 What is your favorite color?_Green\n",
            "43 What is your favorite color?_Red\n",
            "45 What is your favorite color?_Yellow\n",
            "51 Do you enjoy socializing with large groups of people?\n",
            "\n",
            "Hobby: Arts and Craft\n",
            "Best number of features: 3\n",
            "Score: 0.7649462365591397\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "61 Do you like to sit in front of a computer for long hours?\n",
            "\n",
            "Hobby: Food and Drinks\n",
            "Best number of features: 1\n",
            "Score: 0.6929032258064517\n",
            "44 What is your favorite color?_White\n",
            "\n",
            "Hobby: Collecting\n",
            "Best number of features: 1\n",
            "Score: 0.8890322580645161\n",
            "17 Choose a pet which you prefer to keep._Cat\n",
            "\n",
            "Hobby: Rejuvenation\n",
            "Best number of features: 8\n",
            "Score: 0.9150537634408602\n",
            "3 What is your current occupation?_Unemployed\n",
            "4 What is your current occupation?_University student\n",
            "28 What is your favorite time of the day?_Night\n",
            "32 What do you worry more about the most?_The state of the world\n",
            "42 What is your favorite color?_Purple\n",
            "59 Do you have lot of patience?\n",
            "60 Do you organize your schedule well?\n",
            "64 How confident are you in your own abilities?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXrdqvlqFFsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae03c0d-8601-4bfd-ca76-9ce88d361275"
      },
      "source": [
        "#Define all the possible classifiers.\n",
        "parameters = [\n",
        "    {\n",
        "        'classifier': [LogisticRegression(solver='sag')]\n",
        "    },\n",
        "    {\n",
        "        'classifier': [MultinomialNB(fit_prior=True, class_prior=None)]\n",
        "    },\n",
        "    {\n",
        "        'classifier': [LinearSVC()]\n",
        "    }\n",
        "]\n",
        "\n",
        "#Choose the best parameter for the model.\n",
        "clf = GridSearchCV(BinaryRelevance(), parameters, scoring='f1_micro')\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print (clf.best_params_, clf.best_score_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'classifier': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)} 0.5475998015895553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyhzp06swpK1",
        "outputId": "564b2842-5e33-4508-eab2-157d4c751b62"
      },
      "source": [
        "#The best model with some tuning.\n",
        "classifier = BinaryRelevance(\n",
        "    classifier = LogisticRegression(solver='sag'),\n",
        "    require_dense = [False, True]\n",
        ")\n",
        "\n",
        "\n",
        "classifier.fit(x_train, y_train)\n",
        "print(classifier.model_count_)\n",
        "prediction=classifier.predict(x_test)\n",
        "f1=sklearn.metrics.f1_score(y_test, prediction,average=\"micro\")\n",
        "f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5849802371541503"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1NNwGBKenTy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}