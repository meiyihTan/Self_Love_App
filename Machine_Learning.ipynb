{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM86NRYZ5/EB2kxQHYCGvxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandontan99/Self_Love_App/blob/master/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnXKhzrzjYOx"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z0aAfTihkgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1ad4bd-3b88-43cc-aa42-a1bb23929883"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/brandontan99/Self_Love_App.git\n",
        "%cd /content/Self_Love_App\n",
        "!pip install scikit-multilearn\n",
        "\n",
        "import sys \n",
        "sys.path.append(\"./preprocessing\")\n",
        "sys.path.append(\"./utils\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skmultilearn.adapt import *\n",
        "from skmultilearn.problem_transform import *\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from data_cleaning import data_cleaning\n",
        "from Data_Normalization import data_encoding, data_normalization\n",
        "from feature_selection import *\n",
        "\n",
        "# random seed to ensure reproducibility\n",
        "seed = 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Self_Love_App'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 246 (delta 138), reused 67 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (246/246), 2.91 MiB | 9.06 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "/content/Self_Love_App\n",
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsmsNdXyyCm5"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "2P6H4tWRDWaO",
        "outputId": "20a08d81-2f51-4855-adf4-90ee840ab096"
      },
      "source": [
        "# read and preprocess the csv file generated from google form \n",
        "df = pd.read_csv(\"WID3006 ML Questionnaire.csv\")\n",
        "df_cleaned = data_cleaning(df) # clean and group the hobbies \n",
        "df_encoded = data_encoding(df_cleaned) # one-hot encoding \n",
        "df_norm = data_normalization(df_encoded) # normalise the data value to a range from 0 to 1\n",
        "df_norm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender: _Male</th>\n",
              "      <th>What is your current occupation?_Retired</th>\n",
              "      <th>What is your current occupation?_Unemployed</th>\n",
              "      <th>What is your current occupation?_University student</th>\n",
              "      <th>What boosts your confidence ? _By leading others to success</th>\n",
              "      <th>What boosts your confidence ? _Get the most/ special attention among the members</th>\n",
              "      <th>What boosts your confidence ? _When someone acknowledges you</th>\n",
              "      <th>What boosts your confidence ? _When you accomplish a project</th>\n",
              "      <th>I prefer to spend my money on...._Food</th>\n",
              "      <th>I prefer to spend my money on...._Home Improvements</th>\n",
              "      <th>I prefer to spend my money on...._The latest fashion</th>\n",
              "      <th>I prefer to spend my money on...._The latest technology</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper</th>\n",
              "      <th>Choose a pet which you prefer to keep._Cat</th>\n",
              "      <th>Choose a pet which you prefer to keep._Dog</th>\n",
              "      <th>Choose a pet which you prefer to keep._Fish</th>\n",
              "      <th>Choose a pet which you prefer to keep._Hamster</th>\n",
              "      <th>Choose a pet which you prefer to keep._Horse</th>\n",
              "      <th>Choose a pet which you prefer to keep._I'm not a pet person</th>\n",
              "      <th>Choose a pet which you prefer to keep._Rabbit</th>\n",
              "      <th>Choose a pet which you prefer to keep._Snake</th>\n",
              "      <th>Choose a pet which you prefer to keep._Tortoise</th>\n",
              "      <th>What is your favorite time of the day?_Evening</th>\n",
              "      <th>What is your favorite time of the day?_Morning</th>\n",
              "      <th>What is your favorite time of the day?_Night</th>\n",
              "      <th>Would you rather visit the future or the past?_The future</th>\n",
              "      <th>Would you rather visit the future or the past?_The past</th>\n",
              "      <th>What do you worry more about the most?_Money</th>\n",
              "      <th>What do you worry more about the most?_The state of the world</th>\n",
              "      <th>What do you worry more about the most?_Your family and friends</th>\n",
              "      <th>What do you worry more about the most?_Your future</th>\n",
              "      <th>When you retire, you'd like to live..._Exactly where I live now</th>\n",
              "      <th>When you retire, you'd like to live..._In a hectic big city</th>\n",
              "      <th>When you retire, you'd like to live..._In a small town</th>\n",
              "      <th>When you retire, you'd like to live..._Overseas</th>\n",
              "      <th>When you retire, you'd like to live..._Traveling the world</th>\n",
              "      <th>What is your favorite color?_Blue</th>\n",
              "      <th>What is your favorite color?_Green</th>\n",
              "      <th>What is your favorite color?_Purple</th>\n",
              "      <th>What is your favorite color?_Red</th>\n",
              "      <th>What is your favorite color?_White</th>\n",
              "      <th>What is your favorite color?_Yellow</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By attending online courses</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing assignments</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading a physical book</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading an e-Book</th>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <th>Are you a curious person?</th>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "      <th>Sports and Outdoors</th>\n",
              "      <th>Games</th>\n",
              "      <th>Spiritual and Mental</th>\n",
              "      <th>Performing Arts</th>\n",
              "      <th>Arts and Craft</th>\n",
              "      <th>Food and Drinks</th>\n",
              "      <th>Collecting</th>\n",
              "      <th>Rejuvenation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender: _Male  ...  Rejuvenation\n",
              "0                1  ...           0.0\n",
              "1                1  ...           0.0\n",
              "2                1  ...           0.0\n",
              "3                1  ...           0.0\n",
              "4                0  ...           0.0\n",
              "..             ...  ...           ...\n",
              "187              1  ...           0.0\n",
              "188              1  ...           0.0\n",
              "189              1  ...           0.0\n",
              "190              1  ...           0.0\n",
              "191              1  ...           0.0\n",
              "\n",
              "[192 rows x 72 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2MIs9nn6aoU",
        "outputId": "876bef29-6547-44a3-e8a3-6a7b199ff51c"
      },
      "source": [
        "# check the index and the question columns\n",
        "for i, name in enumerate(df_norm.columns):\n",
        "  print(i, name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Gender: _Male\n",
            "1 What is your current occupation?_Retired\n",
            "2 What is your current occupation?_Unemployed\n",
            "3 What is your current occupation?_University student\n",
            "4 What boosts your confidence ? _By leading others to success\n",
            "5 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "6 What boosts your confidence ? _When someone acknowledges you\n",
            "7 What boosts your confidence ? _When you accomplish a project\n",
            "8 I prefer to spend my money on...._Food\n",
            "9 I prefer to spend my money on...._Home Improvements\n",
            "10 I prefer to spend my money on...._The latest fashion\n",
            "11 I prefer to spend my money on...._The latest technology\n",
            "12 How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph\n",
            "13 How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud\n",
            "14 How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar\n",
            "15 How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper\n",
            "16 Choose a pet which you prefer to keep._Cat\n",
            "17 Choose a pet which you prefer to keep._Dog\n",
            "18 Choose a pet which you prefer to keep._Fish\n",
            "19 Choose a pet which you prefer to keep._Hamster\n",
            "20 Choose a pet which you prefer to keep._Horse\n",
            "21 Choose a pet which you prefer to keep._I'm not a pet person\n",
            "22 Choose a pet which you prefer to keep._Rabbit\n",
            "23 Choose a pet which you prefer to keep._Snake\n",
            "24 Choose a pet which you prefer to keep._Tortoise\n",
            "25 What is your favorite time of the day?_Evening\n",
            "26 What is your favorite time of the day?_Morning\n",
            "27 What is your favorite time of the day?_Night\n",
            "28 Would you rather visit the future or the past?_The future\n",
            "29 Would you rather visit the future or the past?_The past\n",
            "30 What do you worry more about the most?_Money\n",
            "31 What do you worry more about the most?_The state of the world\n",
            "32 What do you worry more about the most?_Your family and friends\n",
            "33 What do you worry more about the most?_Your future\n",
            "34 When you retire, you'd like to live..._Exactly where I live now\n",
            "35 When you retire, you'd like to live..._In a hectic big city\n",
            "36 When you retire, you'd like to live..._In a small town\n",
            "37 When you retire, you'd like to live..._Overseas\n",
            "38 When you retire, you'd like to live..._Traveling the world\n",
            "39 What is your favorite color?_Blue\n",
            "40 What is your favorite color?_Green\n",
            "41 What is your favorite color?_Purple\n",
            "42 What is your favorite color?_Red\n",
            "43 What is your favorite color?_White\n",
            "44 What is your favorite color?_Yellow\n",
            "45 What is your learning style? (Pick one that benefit you the most)_By attending online courses\n",
            "46 What is your learning style? (Pick one that benefit you the most)_By doing assignments\n",
            "47 What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions\n",
            "48 What is your learning style? (Pick one that benefit you the most)_By reading a physical book\n",
            "49 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "50 Do you enjoy socializing with large groups of people?\n",
            "51 Do you enjoy challenges?\n",
            "52 How creative of a person do you think you are?\n",
            "53 How logical of a person do you think you are?\n",
            "54 Would you prefer to engage your brain more than your body?\n",
            "55 Are you a curious person?\n",
            "56 Are you a perfectionist?\n",
            "57 Are you a trusting person?\n",
            "58 Do you have lot of patience?\n",
            "59 Do you organize your schedule well?\n",
            "60 Do you like to sit in front of a computer for long hours?\n",
            "61 Do you enjoy making others happy?\n",
            "62 Can you understand others' perspectives and feelings?\n",
            "63 How confident are you in your own abilities?\n",
            "64 Sports and Outdoors\n",
            "65 Games\n",
            "66 Spiritual and Mental\n",
            "67 Performing Arts\n",
            "68 Arts and Craft\n",
            "69 Food and Drinks\n",
            "70 Collecting\n",
            "71 Rejuvenation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "V9fBSm0zrTnq",
        "outputId": "c0e6aa9d-128d-4d44-bead-b0d7abc7b834"
      },
      "source": [
        "# filter the features to be trained on according to the feature importance from rfe or chi2 test\n",
        "x = filter_features(best_k_features, df_norm)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender: _Male</th>\n",
              "      <th>What is your current occupation?_Retired</th>\n",
              "      <th>What is your current occupation?_Unemployed</th>\n",
              "      <th>What is your current occupation?_University student</th>\n",
              "      <th>What boosts your confidence ? _By leading others to success</th>\n",
              "      <th>What boosts your confidence ? _Get the most/ special attention among the members</th>\n",
              "      <th>What boosts your confidence ? _When someone acknowledges you</th>\n",
              "      <th>What boosts your confidence ? _When you accomplish a project</th>\n",
              "      <th>I prefer to spend my money on...._Food</th>\n",
              "      <th>I prefer to spend my money on...._Home Improvements</th>\n",
              "      <th>I prefer to spend my money on...._The latest fashion</th>\n",
              "      <th>I prefer to spend my money on...._The latest technology</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I make a chart or graph</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar</th>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper</th>\n",
              "      <th>Choose a pet which you prefer to keep._Cat</th>\n",
              "      <th>Choose a pet which you prefer to keep._Dog</th>\n",
              "      <th>Choose a pet which you prefer to keep._Fish</th>\n",
              "      <th>Choose a pet which you prefer to keep._Hamster</th>\n",
              "      <th>Choose a pet which you prefer to keep._Horse</th>\n",
              "      <th>Choose a pet which you prefer to keep._I'm not a pet person</th>\n",
              "      <th>Choose a pet which you prefer to keep._Rabbit</th>\n",
              "      <th>Choose a pet which you prefer to keep._Snake</th>\n",
              "      <th>Choose a pet which you prefer to keep._Tortoise</th>\n",
              "      <th>What is your favorite time of the day?_Evening</th>\n",
              "      <th>What is your favorite time of the day?_Morning</th>\n",
              "      <th>What is your favorite time of the day?_Night</th>\n",
              "      <th>What do you worry more about the most?_Money</th>\n",
              "      <th>What do you worry more about the most?_The state of the world</th>\n",
              "      <th>What do you worry more about the most?_Your family and friends</th>\n",
              "      <th>What do you worry more about the most?_Your future</th>\n",
              "      <th>When you retire, you'd like to live..._Exactly where I live now</th>\n",
              "      <th>When you retire, you'd like to live..._In a hectic big city</th>\n",
              "      <th>When you retire, you'd like to live..._In a small town</th>\n",
              "      <th>When you retire, you'd like to live..._Overseas</th>\n",
              "      <th>When you retire, you'd like to live..._Traveling the world</th>\n",
              "      <th>What is your favorite color?_Blue</th>\n",
              "      <th>What is your favorite color?_Green</th>\n",
              "      <th>What is your favorite color?_Purple</th>\n",
              "      <th>What is your favorite color?_Red</th>\n",
              "      <th>What is your favorite color?_White</th>\n",
              "      <th>What is your favorite color?_Yellow</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By attending online courses</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing assignments</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading a physical book</th>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)_By reading an e-Book</th>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender: _Male  ...  How confident are you in your own abilities?\n",
              "0                1  ...                                          0.50\n",
              "1                1  ...                                          1.00\n",
              "2                1  ...                                          0.75\n",
              "3                1  ...                                          0.75\n",
              "4                0  ...                                          1.00\n",
              "..             ...  ...                                           ...\n",
              "187              1  ...                                          0.75\n",
              "188              1  ...                                          0.75\n",
              "189              1  ...                                          0.50\n",
              "190              1  ...                                          0.75\n",
              "191              1  ...                                          0.25\n",
              "\n",
              "[192 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f0n58suGAiy"
      },
      "source": [
        "# split the dataset into features(x) and targets(y)\n",
        "x = df_norm.iloc[:, :64]\n",
        "y = df_norm.iloc[:, 64:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ece3V25n1Gar",
        "outputId": "fcd32727-ec67-4c8b-ecb2-c4d9f0c0f954"
      },
      "source": [
        "# split the dataset into 75% train and 25% test set (validation set is not needed due to the use of K-fold cross validation)\n",
        "test_size = 0.25\n",
        "x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_size, random_state=seed)\n",
        "print(\"Number of train dataset:\", len(x_train))\n",
        "print(\"Number of test dataset:\", len(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train dataset: 144\n",
            "Number of test dataset: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "CEv85eH5JjE7",
        "outputId": "340b5a4f-d867-47b7-c144-14a76ba84c2d"
      },
      "source": [
        "# draw the distribution of the hobbies with a horizontal bar chart\n",
        "distribution_of_hobbies = y.sum().sort_values(ascending=False)\n",
        "distribution_of_hobbies_train_test = pd.DataFrame(np.concatenate([y_train.sum(axis=0)[:,None], y_test.sum(axis=0)[:,None]], axis=1), index=y.columns, columns=[\"Train\",\"Test\"])\n",
        "distribution_of_hobbies_train_test = distribution_of_hobbies_train_test.reindex(distribution_of_hobbies.index)\n",
        "distribution_of_hobbies_train_test.plot(kind='barh', figsize=(6, 6), title=\"Frequency of each Hobbes chosen\", stacked=True)\n",
        "\n",
        "# put the frequency text on the right of the bar chart\n",
        "for i, (row_index, row) in enumerate(distribution_of_hobbies_train_test.iterrows()):\n",
        "  train_value = row[\"Train\"]\n",
        "  test_value = row[\"Test\"]\n",
        "  sum_value = train_value + test_value\n",
        "  plt.text(x=sum_value+1 , y =i , s=f\"{int(train_value)}+{int(test_value)}={int(sum_value)}\" , fontdict=dict(fontsize=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "e87w3nOWnUGH",
        "outputId": "21ffe6c9-96f8-4c3b-ff32-9d7e242617d3"
      },
      "source": [
        "# draw the histogram of the number of hobbies for each person\n",
        "y.sum(axis=1).plot.hist(title='Histogram of the number of hobbies for each person')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fbf605550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72fDWLw4mk4B"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEjgylVW-zQg"
      },
      "source": [
        "### Define the models with a list of hyperparameters of the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebGiWvLqlQFt"
      },
      "source": [
        "# Base Classifiers ( dict format --> (name, func) : params )\n",
        "base_models = {\n",
        "    (\"Decision_Tree\", DecisionTreeClassifier) : {'min_samples_split':range(2,5) , 'min_samples_leaf':range(1,4),'min_weight_fraction_leaf':[0.0,0.5],'random_state':[seed]},\n",
        "    (\"Extra_Trees\", ExtraTreesClassifier) : {'n_estimators':range(90,120,10),'min_samples_split':range(2,5) , 'min_samples_leaf':range(1,4),'n_jobs':[-1],'random_state':[seed]},\n",
        "    (\"Random_Forest\", RandomForestClassifier) :{'n_estimators':range(90,120,10),'min_samples_split':range(2,5),'min_samples_leaf':range(1,4),'n_jobs':[-1],'random_state':[seed]},\n",
        "    (\"MLP\", MLPClassifier) : {'hidden_layer_sizes': [(128,64,32),(64,32),(64)],'alpha':[1e-3, 1e-2, 1e-1], 'max_iter': [2000],'random_state':[seed]},\n",
        "    (\"Ridge\", RidgeClassifierCV) : {'fit_intercept':[True]}\n",
        "}\n",
        "\n",
        "# Adaptation approaches\n",
        "adapt_models = {\n",
        "    (\"Binary_Relevance_kNN_A\", BRkNNaClassifier) : {'k': range(1,3)},\n",
        "    (\"Binary_Relevance_kNN_B\", BRkNNbClassifier) : {'k': range(1,3)},\n",
        "    (\"Multi-Label_KNN\", MLkNN) : {'k': range(1,3), 's': [0.5, 0.7, 1.0]},\n",
        "    (\"ARAM_Neural_Network\", MLARAM) : {'threshold':[0.05], 'vigilance':[0.95]},\n",
        "    (\"Twin_SVM\", MLTSVM) : {'c_k': [2**i for i in range(-5, 5, 2)]} # need sparse input\n",
        "}\n",
        "\n",
        "# Problem Transformation\n",
        "problem_transform = {\n",
        "    \"Binary_Relevance\" : BinaryRelevance,\n",
        "    \"Classifier_Chain\" : ClassifierChain\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK2OVicp3RRN"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poag9j9Y3UbR"
      },
      "source": [
        "# Hyperparameters Tuning\n",
        "num_of_kfold_splits = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrPDLJ_sEZJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBR9K5X1hhUX"
      },
      "source": [
        "### Adaptation approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw7j6Fj5hgOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717e2fe5-9cc2-4caa-bad9-606986d81fd4"
      },
      "source": [
        "results = {}\n",
        "scoring = 'f1_micro' # to evaluate on imbalanced dataset\n",
        "y_sparse = sparse.csr_matrix(y_train)\n",
        "x_sparse = sparse.csr_matrix(x_train)\n",
        "for (model_name, model), params in adapt_models.items():\n",
        "  kfold = KFold(n_splits=num_of_kfold_splits, random_state=None)\n",
        "  # use GridSearchCV to find the best hyperparameters and use cross validation to train on train and validation set eventually\n",
        "  clf = GridSearchCV(model(), params, cv=kfold, n_jobs=-1, scoring=scoring) \n",
        "  if model_name == \"Twin_SVM\": # this model need sparse input\n",
        "    clf.fit(x_sparse, y_sparse)\n",
        "  else:\n",
        "    clf.fit(x_train, y_train)\n",
        "  results[model_name] = clf\n",
        "  print(model_name,clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary_Relevance_kNN_A 0.4823135496896695\n",
            "Binary_Relevance_kNN_B 0.22701983420659094\n",
            "Multi-Label_KNN 0.4823135496896695\n",
            "ARAM_Neural_Network 0.48741973938422334\n",
            "Twin_SVM 0.5322630549362678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTInTnWiJ7H"
      },
      "source": [
        "### Problem Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFCZquVjYFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a13b7a2-05fa-4863-b5df-4d45127de766"
      },
      "source": [
        "scoring = 'f1_micro' # to evaluate on imbalanced dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_size, random_state=seed)\n",
        "for strategy_name, strategy in problem_transform.items():\n",
        "  for (model_name, model), params in base_models.items():\n",
        "    parameters = {}\n",
        "    for param_name, param_value in params.items():\n",
        "      parameters[\"classifier__\"+param_name] = param_value\n",
        "    kfold = KFold(n_splits=num_of_kfold_splits, random_state=None) \n",
        "    # use GridSearchCV to find the best hyperparameters and use cross validation to train on train and validation set eventually\n",
        "    clf = GridSearchCV(strategy(classifier=model()), parameters, cv=kfold, n_jobs=-1, scoring=scoring) \n",
        "    clf.fit(x_train, y_train)\n",
        "    results[f\"{strategy_name}_{model_name}\"] = clf\n",
        "    print(f\"{strategy_name}_{model_name}\",clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary_Relevance_Extra_Trees 0.554058698870729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvWdCMwxmfLx"
      },
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHuyET4zxwoy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "9b96247a-6edf-4f81-99ec-f665a7dac216"
      },
      "source": [
        "def display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\"):\n",
        "  result_table = []\n",
        "  for model_name, model in results.items():\n",
        "    y_pred = model.predict(x_test)\n",
        "    score = f1_score(y_test, y_pred, average=f1_average)\n",
        "    score_by_class = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
        "    result_table.append([score]+score_by_class.tolist())\n",
        "\n",
        "  # f1 score evaluation result overall and by class in percentage \n",
        "  # 0 means no True Positive at all or there is no example of that class in the y_text at all\n",
        "  result_table_df = pd.DataFrame(result_table, columns=[\"Overall\"]+y.columns.tolist(), index=results.keys()) * 100\n",
        "  result_table_df.sort_values(by='Overall', inplace=True, ascending=False)\n",
        "\n",
        "  # arrange the columns according to the frequency of each hobbies in the test set\n",
        "  sorted_columns = distribution_of_hobbies_train_test[\"Test\"].sort_values(ascending=False).index.tolist()\n",
        "  modified_column_names = [column + \"(\" + str(int(distribution_of_hobbies_train_test.loc[column,\"Test\"]))+\")\" for column in sorted_columns]\n",
        "  result_table_df = result_table_df[[\"Overall\"] + sorted_columns] # sort the columns by the frequency of each hobbies in the test set \n",
        "  result_table_df.columns = [[\"Overall\"] + modified_column_names] # add the frequency of each hobbies in the test set beside the column name\n",
        "  return result_table_df\n",
        "\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Spiritual and Mental(27)</th>\n",
              "      <th>Games(26)</th>\n",
              "      <th>Sports and Outdoors(25)</th>\n",
              "      <th>Performing Arts(18)</th>\n",
              "      <th>Food and Drinks(10)</th>\n",
              "      <th>Arts and Craft(9)</th>\n",
              "      <th>Rejuvenation(7)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>61.847390</td>\n",
              "      <td>78.787879</td>\n",
              "      <td>67.741935</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>61.596958</td>\n",
              "      <td>78.688525</td>\n",
              "      <td>77.192982</td>\n",
              "      <td>70.588235</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>60.728745</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>67.857143</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>60.483871</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>73.684211</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>60.240964</td>\n",
              "      <td>78.787879</td>\n",
              "      <td>67.857143</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>59.751037</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>70.175439</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>58.333333</td>\n",
              "      <td>76.056338</td>\n",
              "      <td>70.175439</td>\n",
              "      <td>64.150943</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>57.480315</td>\n",
              "      <td>74.576271</td>\n",
              "      <td>75.471698</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>42.105263</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>53.260870</td>\n",
              "      <td>68.656716</td>\n",
              "      <td>75.362319</td>\n",
              "      <td>68.852459</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>31.818182</td>\n",
              "      <td>35.897436</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>8.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>50.549451</td>\n",
              "      <td>76.190476</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>50.980392</td>\n",
              "      <td>36.842105</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>49.792531</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>48.872180</td>\n",
              "      <td>74.576271</td>\n",
              "      <td>57.692308</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>28.352490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.658537</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>31.578947</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>19.512195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Collecting(4)\n",
              "Binary_Relevance_Random_Forest  61.847390  ...      0.000000\n",
              "Binary_Relevance_MLP            61.596958  ...      0.000000\n",
              "Classifier_Chain_Ridge          60.728745  ...      0.000000\n",
              "Classifier_Chain_Extra_Trees    60.483871  ...      0.000000\n",
              "Binary_Relevance_Ridge          60.240964  ...      0.000000\n",
              "Binary_Relevance_Extra_Trees    59.751037  ...      0.000000\n",
              "Classifier_Chain_Random_Forest  58.333333  ...      0.000000\n",
              "Binary_Relevance_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_MLP            57.480315  ...      0.000000\n",
              "Twin_SVM                        53.260870  ...      8.695652\n",
              "ARAM_Neural_Network             50.549451  ...     20.000000\n",
              "Multi-Label_KNN                 49.792531  ...     40.000000\n",
              "Binary_Relevance_kNN_A          48.872180  ...     22.222222\n",
              "Binary_Relevance_kNN_B          28.352490  ...     19.512195\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP1k4bwaiAaw"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2f817ktGJg"
      },
      "source": [
        "### Chi Square Analysis\n",
        "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Fm_P4vKEh_cT",
        "outputId": "42c41242-5017-4432-82be-863a22e5104d"
      },
      "source": [
        "# label encoding is used instead of one-hot encoding because one-hot encoding will create many features for one question\n",
        "# but label encoding is able to perform chi-square test between a single question as a whole and the hobby  \n",
        "x_df, y_df = label_encoding(df_cleaned)\n",
        "# only evaluate on train data to prevent data leakage\n",
        "x_train_label_encoded, _, y_train, _ = train_test_split(x_df.to_numpy(), y_df.to_numpy(), test_size=test_size, random_state=seed)\n",
        "chi2_result = chi2_analysis(x_train_label_encoded, x_df, y_train)\n",
        "chi2_result "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gender:</th>\n",
              "      <td>3.764270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite color?</th>\n",
              "      <td>2.842968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Choose a pet which you prefer to keep.</th>\n",
              "      <td>1.751194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
              "      <td>1.496273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>When you retire, you'd like to live...</th>\n",
              "      <td>1.012028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "      <td>0.912921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
              "      <td>0.878989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What boosts your confidence ?</th>\n",
              "      <td>0.863392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <td>0.848999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <td>0.847976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <td>0.827107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <td>0.577003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What do you worry more about the most?</th>\n",
              "      <td>0.515019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <td>0.509174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <td>0.431427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <td>0.403807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your current occupation?</th>\n",
              "      <td>0.389529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite time of the day?</th>\n",
              "      <td>0.380424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I prefer to spend my money on....</th>\n",
              "      <td>0.317708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <td>0.297015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <td>0.247060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <td>0.246778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you rather visit the future or the past?</th>\n",
              "      <td>0.192822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <td>0.140012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <td>0.090494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a curious person?</th>\n",
              "      <td>0.079047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           0\n",
              "Gender:                                             3.764270\n",
              "What is your favorite color?                        2.842968\n",
              "Choose a pet which you prefer to keep.              1.751194\n",
              "How do you organize your thoughts? Please pick ...  1.496273\n",
              "When you retire, you'd like to live...              1.012028\n",
              "How confident are you in your own abilities?        0.912921\n",
              "What is your learning style? (Pick one that ben...  0.878989\n",
              "What boosts your confidence ?                       0.863392\n",
              "Do you like to sit in front of a computer for l...  0.848999\n",
              "Do you organize your schedule well?                 0.847976\n",
              "Do you enjoy socializing with large groups of p...  0.827107\n",
              "Do you enjoy challenges?                            0.577003\n",
              "What do you worry more about the most?              0.515019\n",
              "Do you have lot of patience?                        0.509174\n",
              "How creative of a person do you think you are?      0.431427\n",
              "Are you a perfectionist?                            0.403807\n",
              "What is your current occupation?                    0.389529\n",
              "What is your favorite time of the day?              0.380424\n",
              "I prefer to spend my money on....                   0.317708\n",
              "How logical of a person do you think you are?       0.297015\n",
              "Would you prefer to engage your brain more than...  0.247060\n",
              "Do you enjoy making others happy?                   0.246778\n",
              "Would you rather visit the future or the past?      0.192822\n",
              "Are you a trusting person?                          0.140012\n",
              "Can you understand others' perspectives and fee...  0.090494\n",
              "Are you a curious person?                           0.079047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhFGPI3cAXYZ"
      },
      "source": [
        "The table above shows the score for each questions with respect to the hobbies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKBiDhjAtB9D"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bFvie1ugfe",
        "outputId": "2dcb7d48-6103-47aa-c8e2-a43fb2c9909c"
      },
      "source": [
        "# train and evaluate the model with top k best features to determine the best number of features\n",
        "# Binary Relevance of ExtraTreesClassifier is used in this case\n",
        "params = base_models[(\"Extra_Trees\", ExtraTreesClassifier)]\n",
        "params = {\"classifier__\"+param_name:param for param_name, param in params.items()}\n",
        "params[\"classifier\"] = [ExtraTreesClassifier()]\n",
        "scoring = 'f1_micro'\n",
        "\n",
        "results = {}\n",
        "for i in range(len(chi2_result.index)):\n",
        "  best_k_features = select_best_k_features(chi2_result, k=i+1)\n",
        "  x = filter_features(best_k_features, df_norm)\n",
        "  x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_size, random_state=seed)\n",
        "  clf = GridSearchCV(BinaryRelevance(), params, cv=5, n_jobs=-1, scoring=scoring)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  score = f1_score(y_test, y_pred, average=\"micro\")\n",
        "  print(\"Number of best k features:\", len(best_k_features), \"score:\",score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of best k features: 1 score: 0.5045871559633027\n",
            "Number of best k features: 2 score: 0.547008547008547\n",
            "Number of best k features: 3 score: 0.5477178423236514\n",
            "Number of best k features: 4 score: 0.5414847161572052\n",
            "Number of best k features: 5 score: 0.5316455696202531\n",
            "Number of best k features: 6 score: 0.5583333333333333\n",
            "Number of best k features: 7 score: 0.5819672131147541\n",
            "Number of best k features: 8 score: 0.6260162601626018\n",
            "Number of best k features: 9 score: 0.6008230452674898\n",
            "Number of best k features: 10 score: 0.5991902834008097\n",
            "Number of best k features: 11 score: 0.5867768595041322\n",
            "Number of best k features: 12 score: 0.5941422594142258\n",
            "Number of best k features: 13 score: 0.6040816326530611\n",
            "Number of best k features: 14 score: 0.5748987854251012\n",
            "Number of best k features: 15 score: 0.5843621399176955\n",
            "Number of best k features: 16 score: 0.6122448979591836\n",
            "Number of best k features: 17 score: 0.5943775100401607\n",
            "Number of best k features: 18 score: 0.592\n",
            "Number of best k features: 19 score: 0.6178861788617885\n",
            "Number of best k features: 20 score: 0.6141078838174274\n",
            "Number of best k features: 21 score: 0.6147540983606558\n",
            "Number of best k features: 22 score: 0.6008230452674898\n",
            "Number of best k features: 23 score: 0.620408163265306\n",
            "Number of best k features: 24 score: 0.5983606557377049\n",
            "Number of best k features: 25 score: 0.6090534979423867\n",
            "Number of best k features: 26 score: 0.5975103734439834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-sASJF8B3h8"
      },
      "source": [
        "Based on the scores above, the best number of features is 8 with 62.6% f1_micro score followed by 23 with 62.04% f1_micro score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3XEZEvymjl8",
        "outputId": "35fe160a-c6d8-41b2-a389-bda4ba362a6f"
      },
      "source": [
        "# 8 questions as the features has the best result\n",
        "best_k_features = select_best_k_features(chi2_result, k=8)\n",
        "best_k_features # below is the list of top 8 questions "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender: ',\n",
              " 'What is your favorite color?',\n",
              " 'Choose a pet which you prefer to keep.',\n",
              " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
              " \"When you retire, you'd like to live...\",\n",
              " 'How confident are you in your own abilities?',\n",
              " 'What is your learning style? (Pick one that benefit you the most)',\n",
              " 'What boosts your confidence ? ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "Gdl2urH2sseB",
        "outputId": "5e67ea8f-c41a-445d-83d9-5fbda8cacea5"
      },
      "source": [
        "# 8 questions as the features are trained and evaluated on all models\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Spiritual and Mental(27)</th>\n",
              "      <th>Games(26)</th>\n",
              "      <th>Sports and Outdoors(25)</th>\n",
              "      <th>Performing Arts(18)</th>\n",
              "      <th>Food and Drinks(10)</th>\n",
              "      <th>Arts and Craft(9)</th>\n",
              "      <th>Rejuvenation(7)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>62.601626</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>67.796610</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>59.315589</td>\n",
              "      <td>77.777778</td>\n",
              "      <td>68.965517</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>48.780488</td>\n",
              "      <td>34.782609</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>58.687259</td>\n",
              "      <td>81.355932</td>\n",
              "      <td>67.741935</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>42.105263</td>\n",
              "      <td>21.052632</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>57.983193</td>\n",
              "      <td>78.260870</td>\n",
              "      <td>65.517241</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>37.037037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>57.851240</td>\n",
              "      <td>76.470588</td>\n",
              "      <td>61.016949</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>48.275862</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>57.740586</td>\n",
              "      <td>78.787879</td>\n",
              "      <td>65.517241</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>57.740586</td>\n",
              "      <td>76.470588</td>\n",
              "      <td>59.649123</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>55.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>59.259259</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>19.047619</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>28.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>50.566038</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>73.076923</td>\n",
              "      <td>29.268293</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>21.052632</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>18.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>50.356295</td>\n",
              "      <td>73.239437</td>\n",
              "      <td>67.692308</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>56.140351</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>11.764706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>48.120301</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>53.061224</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>29.629630</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>48.120301</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>53.061224</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>29.629630</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>24.031008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>19.047619</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>9.523810</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>9.302326</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Collecting(4)\n",
              "Binary_Relevance_Extra_Trees    62.601626  ...      0.000000\n",
              "Binary_Relevance_MLP            59.315589  ...     25.000000\n",
              "Classifier_Chain_Extra_Trees    58.687259  ...      0.000000\n",
              "Binary_Relevance_Random_Forest  57.983193  ...      0.000000\n",
              "Binary_Relevance_Ridge          57.851240  ...      0.000000\n",
              "Binary_Relevance_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_Random_Forest  57.740586  ...      0.000000\n",
              "Classifier_Chain_Ridge          57.740586  ...      0.000000\n",
              "Classifier_Chain_MLP            55.200000  ...     28.571429\n",
              "ARAM_Neural_Network             50.566038  ...     18.181818\n",
              "Twin_SVM                        50.356295  ...     11.764706\n",
              "Binary_Relevance_kNN_A          48.120301  ...     20.000000\n",
              "Multi-Label_KNN                 48.120301  ...     20.000000\n",
              "Binary_Relevance_kNN_B          24.031008  ...      9.302326\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVDbSUN7Ab3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57766333-7baf-4612-8743-4127308ba523"
      },
      "source": [
        "# 23 questions as features has the second best result\n",
        "best_k_features = select_best_k_features(chi2_result, k=23)\n",
        "best_k_features # below is the list of top 23 questions "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender: ',\n",
              " 'What is your favorite color?',\n",
              " 'Choose a pet which you prefer to keep.',\n",
              " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
              " \"When you retire, you'd like to live...\",\n",
              " 'How confident are you in your own abilities?',\n",
              " 'What is your learning style? (Pick one that benefit you the most)',\n",
              " 'What boosts your confidence ? ',\n",
              " 'Do you like to sit in front of a computer for long hours?',\n",
              " 'Do you organize your schedule well?',\n",
              " 'Do you enjoy socializing with large groups of people?',\n",
              " 'Do you enjoy challenges?',\n",
              " 'What do you worry more about the most?',\n",
              " 'Do you have lot of patience?',\n",
              " 'How creative of a person do you think you are?',\n",
              " 'Are you a perfectionist?',\n",
              " 'What is your current occupation?',\n",
              " 'What is your favorite time of the day?',\n",
              " 'I prefer to spend my money on....',\n",
              " 'How logical of a person do you think you are?',\n",
              " 'Would you prefer to engage your brain more than your body?',\n",
              " 'Do you enjoy making others happy?',\n",
              " 'Would you rather visit the future or the past?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2LWHIfrAirQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "3b68c73c-87bd-443f-d06e-e2ea8fc3bf4a"
      },
      "source": [
        "# 23 questions as features are trained and evaluated on all models\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Spiritual and Mental(27)</th>\n",
              "      <th>Games(26)</th>\n",
              "      <th>Sports and Outdoors(25)</th>\n",
              "      <th>Performing Arts(18)</th>\n",
              "      <th>Food and Drinks(10)</th>\n",
              "      <th>Arts and Craft(9)</th>\n",
              "      <th>Rejuvenation(7)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>62.040816</td>\n",
              "      <td>79.411765</td>\n",
              "      <td>75.862069</td>\n",
              "      <td>65.384615</td>\n",
              "      <td>45.714286</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>61.596958</td>\n",
              "      <td>81.967213</td>\n",
              "      <td>70.370370</td>\n",
              "      <td>70.588235</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>38.095238</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>61.538462</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>77.192982</td>\n",
              "      <td>70.588235</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>47.058824</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>61.344538</td>\n",
              "      <td>82.539683</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>65.384615</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>60.975610</td>\n",
              "      <td>76.470588</td>\n",
              "      <td>72.131148</td>\n",
              "      <td>69.090909</td>\n",
              "      <td>41.379310</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>59.919028</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>69.090909</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>59.259259</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>71.186441</td>\n",
              "      <td>64.150943</td>\n",
              "      <td>34.482759</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>58.730159</td>\n",
              "      <td>77.611940</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>53.950954</td>\n",
              "      <td>70.588235</td>\n",
              "      <td>72.463768</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>37.837838</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>16.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>50.746269</td>\n",
              "      <td>76.666667</td>\n",
              "      <td>62.962963</td>\n",
              "      <td>50.980392</td>\n",
              "      <td>39.024390</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>49.446494</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>57.692308</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>46.586345</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>67.692308</td>\n",
              "      <td>43.902439</td>\n",
              "      <td>25.806452</td>\n",
              "      <td>31.578947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.813953</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.586207</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>14.634146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Collecting(4)\n",
              "Binary_Relevance_Extra_Trees    62.040816  ...      0.000000\n",
              "Binary_Relevance_MLP            61.596958  ...     22.222222\n",
              "Classifier_Chain_MLP            61.538462  ...     25.000000\n",
              "Classifier_Chain_Extra_Trees    61.344538  ...      0.000000\n",
              "Binary_Relevance_Random_Forest  60.975610  ...      0.000000\n",
              "Classifier_Chain_Ridge          59.919028  ...      0.000000\n",
              "Classifier_Chain_Random_Forest  59.259259  ...      0.000000\n",
              "Binary_Relevance_Ridge          58.730159  ...      0.000000\n",
              "Binary_Relevance_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_Decision_Tree  57.777778  ...      0.000000\n",
              "Twin_SVM                        53.950954  ...     16.666667\n",
              "Binary_Relevance_kNN_A          50.746269  ...     22.222222\n",
              "ARAM_Neural_Network             49.446494  ...     22.222222\n",
              "Multi-Label_KNN                 46.586345  ...     40.000000\n",
              "Binary_Relevance_kNN_B          28.571429  ...     14.634146\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aVEjdKRwDBu"
      },
      "source": [
        "### Recursive Feature Elimination (rfe)\n",
        "https://machinelearningmastery.com/rfe-feature-selection-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUq8Tc0Ydbit",
        "outputId": "b510f9f0-1762-4b8f-ff8b-97385258a025"
      },
      "source": [
        "# rfe is used with Logistic Regression as the estimator \n",
        "rfe_result = rfe_cv(x_train, y_train, x.columns, y.columns, LogisticRegression())\n",
        "# below shows that k number of features is needed only to obtain the best score to predict the hobby"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hobby: Sports and Outdoors\n",
            "Best number of features: 16\n",
            "Score: 0.7086206896551724\n",
            "1 Gender: _Male\n",
            "21 Choose a pet which you prefer to keep._Horse\n",
            "23 Choose a pet which you prefer to keep._Rabbit\n",
            "25 Choose a pet which you prefer to keep._Tortoise\n",
            "26 What is your favorite time of the day?_Evening\n",
            "31 What do you worry more about the most?_Money\n",
            "40 What is your favorite color?_Blue\n",
            "43 What is your favorite color?_Red\n",
            "45 What is your favorite color?_Yellow\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "55 Would you prefer to engage your brain more than your body?\n",
            "57 Are you a perfectionist?\n",
            "58 Are you a trusting person?\n",
            "59 Do you have lot of patience?\n",
            "64 How confident are you in your own abilities?\n",
            "\n",
            "Hobby: Games\n",
            "Best number of features: 43\n",
            "Score: 0.5832512315270936\n",
            "1 Gender: _Male\n",
            "2 What is your current occupation?_Retired\n",
            "3 What is your current occupation?_Unemployed\n",
            "4 What is your current occupation?_University student\n",
            "5 What boosts your confidence ? _By leading others to success\n",
            "6 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "7 What boosts your confidence ? _When someone acknowledges you\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "9 I prefer to spend my money on...._Food\n",
            "10 I prefer to spend my money on...._Home Improvements\n",
            "11 I prefer to spend my money on...._The latest fashion\n",
            "14 How do you organize your thoughts? Please pick whichever is closest._I talk to myself out loud\n",
            "15 How do you organize your thoughts? Please pick whichever is closest._I write it down in my calendar\n",
            "16 How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper\n",
            "22 Choose a pet which you prefer to keep._I'm not a pet person\n",
            "24 Choose a pet which you prefer to keep._Snake\n",
            "25 Choose a pet which you prefer to keep._Tortoise\n",
            "27 What is your favorite time of the day?_Morning\n",
            "31 What do you worry more about the most?_Money\n",
            "33 What do you worry more about the most?_Your family and friends\n",
            "35 When you retire, you'd like to live..._Exactly where I live now\n",
            "36 When you retire, you'd like to live..._In a hectic big city\n",
            "39 When you retire, you'd like to live..._Traveling the world\n",
            "40 What is your favorite color?_Blue\n",
            "41 What is your favorite color?_Green\n",
            "42 What is your favorite color?_Purple\n",
            "44 What is your favorite color?_White\n",
            "45 What is your favorite color?_Yellow\n",
            "46 What is your learning style? (Pick one that benefit you the most)_By attending online courses\n",
            "47 What is your learning style? (Pick one that benefit you the most)_By doing assignments\n",
            "48 What is your learning style? (Pick one that benefit you the most)_By doing tutorial/lab questions\n",
            "49 What is your learning style? (Pick one that benefit you the most)_By reading a physical book\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "51 Do you enjoy socializing with large groups of people?\n",
            "52 Do you enjoy challenges?\n",
            "54 How logical of a person do you think you are?\n",
            "55 Would you prefer to engage your brain more than your body?\n",
            "58 Are you a trusting person?\n",
            "59 Do you have lot of patience?\n",
            "60 Do you organize your schedule well?\n",
            "61 Do you like to sit in front of a computer for long hours?\n",
            "62 Do you enjoy making others happy?\n",
            "63 Can you understand others' perspectives and feelings?\n",
            "\n",
            "Hobby: Spiritual and Mental\n",
            "Best number of features: 15\n",
            "Score: 0.6317733990147784\n",
            "1 Gender: _Male\n",
            "6 What boosts your confidence ? _Get the most/ special attention among the members\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "24 Choose a pet which you prefer to keep._Snake\n",
            "30 Would you rather visit the future or the past?_The past\n",
            "31 What do you worry more about the most?_Money\n",
            "36 When you retire, you'd like to live..._In a hectic big city\n",
            "43 What is your favorite color?_Red\n",
            "44 What is your favorite color?_White\n",
            "50 What is your learning style? (Pick one that benefit you the most)_By reading an e-Book\n",
            "52 Do you enjoy challenges?\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "62 Do you enjoy making others happy?\n",
            "63 Can you understand others' perspectives and feelings?\n",
            "\n",
            "Hobby: Performing Arts\n",
            "Best number of features: 8\n",
            "Score: 0.646551724137931\n",
            "1 Gender: _Male\n",
            "8 What boosts your confidence ? _When you accomplish a project\n",
            "19 Choose a pet which you prefer to keep._Fish\n",
            "27 What is your favorite time of the day?_Morning\n",
            "31 What do you worry more about the most?_Money\n",
            "36 When you retire, you'd like to live..._In a hectic big city\n",
            "41 What is your favorite color?_Green\n",
            "43 What is your favorite color?_Red\n",
            "\n",
            "Hobby: Arts and Craft\n",
            "Best number of features: 3\n",
            "Score: 0.756896551724138\n",
            "53 How creative of a person do you think you are?\n",
            "54 How logical of a person do you think you are?\n",
            "62 Do you enjoy making others happy?\n",
            "\n",
            "Hobby: Food and Drinks\n",
            "Best number of features: 9\n",
            "Score: 0.7288177339901478\n",
            "16 How do you organize your thoughts? Please pick whichever is closest._Jotting it down on a scrap of paper\n",
            "18 Choose a pet which you prefer to keep._Dog\n",
            "21 Choose a pet which you prefer to keep._Horse\n",
            "26 What is your favorite time of the day?_Evening\n",
            "28 What is your favorite time of the day?_Night\n",
            "43 What is your favorite color?_Red\n",
            "44 What is your favorite color?_White\n",
            "51 Do you enjoy socializing with large groups of people?\n",
            "52 Do you enjoy challenges?\n",
            "\n",
            "Hobby: Collecting\n",
            "Best number of features: 1\n",
            "Score: 0.8820197044334975\n",
            "17 Choose a pet which you prefer to keep._Cat\n",
            "\n",
            "Hobby: Rejuvenation\n",
            "Best number of features: 4\n",
            "Score: 0.9167487684729064\n",
            "4 What is your current occupation?_University student\n",
            "59 Do you have lot of patience?\n",
            "60 Do you organize your schedule well?\n",
            "64 How confident are you in your own abilities?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9GXqrMn51rR"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpvUp9Gh6RBn",
        "outputId": "4da7c5f3-1119-4e30-c1d7-60691485ff92"
      },
      "source": [
        "# train and evaluate the model with top k best features to determine the best number of features\n",
        "# Binary Relevance of ExtraTreesClassifier is used in this case\n",
        "params = base_models[(\"Extra_Trees\", ExtraTreesClassifier)]\n",
        "params = {\"classifier__\"+param_name:param for param_name, param in params.items()}\n",
        "params[\"classifier\"] = [ExtraTreesClassifier()]\n",
        "scoring = 'f1_micro'\n",
        "\n",
        "results = {}\n",
        "for i in range(len(rfe_result.index)):\n",
        "  best_k_features = select_best_k_features(rfe_result, k=i+1)\n",
        "  x = filter_features(best_k_features, df_norm)\n",
        "  x_numpy, y_numpy = x.to_numpy(), y.to_numpy()\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_size, random_state=seed)\n",
        "  clf = GridSearchCV(BinaryRelevance(), params, cv=5, n_jobs=-1, scoring=scoring)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  score = f1_score(y_test, y_pred, average=\"micro\")\n",
        "  print(\"Number of best k features:\", len(best_k_features), \"score:\",score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of best k features: 1 score: 0.5045871559633027\n",
            "Number of best k features: 2 score: 0.547008547008547\n",
            "Number of best k features: 3 score: 0.5714285714285715\n",
            "Number of best k features: 4 score: 0.6097560975609756\n",
            "Number of best k features: 5 score: 0.5774058577405857\n",
            "Number of best k features: 6 score: 0.5500000000000002\n",
            "Number of best k features: 7 score: 0.5606694560669455\n",
            "Number of best k features: 8 score: 0.5596707818930041\n",
            "Number of best k features: 9 score: 0.5409836065573771\n",
            "Number of best k features: 10 score: 0.5857740585774059\n",
            "Number of best k features: 11 score: 0.5555555555555556\n",
            "Number of best k features: 12 score: 0.5787234042553191\n",
            "Number of best k features: 13 score: 0.6048387096774194\n",
            "Number of best k features: 14 score: 0.5966386554621849\n",
            "Number of best k features: 15 score: 0.5916666666666667\n",
            "Number of best k features: 16 score: 0.6033057851239669\n",
            "Number of best k features: 17 score: 0.5892116182572614\n",
            "Number of best k features: 18 score: 0.5916666666666667\n",
            "Number of best k features: 19 score: 0.617283950617284\n",
            "Number of best k features: 20 score: 0.6122448979591836\n",
            "Number of best k features: 21 score: 0.6\n",
            "Number of best k features: 22 score: 0.6008230452674898\n",
            "Number of best k features: 23 score: 0.6\n",
            "Number of best k features: 24 score: 0.6229508196721311\n",
            "Number of best k features: 25 score: 0.6090534979423867\n",
            "Number of best k features: 26 score: 0.5975103734439834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTt7SrDixiTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "7a830338-9e1a-4535-a465-d5810867b287"
      },
      "source": [
        "rfe_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Question</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gender:</th>\n",
              "      <td>12.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite color?</th>\n",
              "      <td>16.604167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a perfectionist?</th>\n",
              "      <td>17.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy socializing with large groups of people?</th>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you have lot of patience?</th>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What do you worry more about the most?</th>\n",
              "      <td>18.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you organize your schedule well?</th>\n",
              "      <td>18.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a trusting person?</th>\n",
              "      <td>20.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy challenges?</th>\n",
              "      <td>20.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you like to sit in front of a computer for long hours?</th>\n",
              "      <td>20.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How creative of a person do you think you are?</th>\n",
              "      <td>20.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How confident are you in your own abilities?</th>\n",
              "      <td>20.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What boosts your confidence ?</th>\n",
              "      <td>22.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>When you retire, you'd like to live...</th>\n",
              "      <td>23.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your favorite time of the day?</th>\n",
              "      <td>23.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Do you enjoy making others happy?</th>\n",
              "      <td>24.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How logical of a person do you think you are?</th>\n",
              "      <td>24.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I prefer to spend my money on....</th>\n",
              "      <td>24.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Choose a pet which you prefer to keep.</th>\n",
              "      <td>25.986111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Can you understand others' perspectives and feelings?</th>\n",
              "      <td>26.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your learning style? (Pick one that benefit you the most)</th>\n",
              "      <td>27.225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How do you organize your thoughts? Please pick whichever is closest.</th>\n",
              "      <td>27.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you prefer to engage your brain more than your body?</th>\n",
              "      <td>28.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is your current occupation?</th>\n",
              "      <td>28.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Would you rather visit the future or the past?</th>\n",
              "      <td>29.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are you a curious person?</th>\n",
              "      <td>31.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            0\n",
              "Question                                                     \n",
              "Gender:                                             12.750000\n",
              "What is your favorite color?                        16.604167\n",
              "Are you a perfectionist?                            17.500000\n",
              "Do you enjoy socializing with large groups of p...  18.000000\n",
              "Do you have lot of patience?                        18.000000\n",
              "What do you worry more about the most?              18.375000\n",
              "Do you organize your schedule well?                 18.750000\n",
              "Are you a trusting person?                          20.500000\n",
              "Do you enjoy challenges?                            20.625000\n",
              "Do you like to sit in front of a computer for l...  20.625000\n",
              "How creative of a person do you think you are?      20.875000\n",
              "How confident are you in your own abilities?        20.875000\n",
              "What boosts your confidence ?                       22.625000\n",
              "When you retire, you'd like to live...              23.400000\n",
              "What is your favorite time of the day?              23.666667\n",
              "Do you enjoy making others happy?                   24.500000\n",
              "How logical of a person do you think you are?       24.500000\n",
              "I prefer to spend my money on....                   24.875000\n",
              "Choose a pet which you prefer to keep.              25.986111\n",
              "Can you understand others' perspectives and fee...  26.750000\n",
              "What is your learning style? (Pick one that ben...  27.225000\n",
              "How do you organize your thoughts? Please pick ...  27.593750\n",
              "Would you prefer to engage your brain more than...  28.750000\n",
              "What is your current occupation?                    28.833333\n",
              "Would you rather visit the future or the past?      29.812500\n",
              "Are you a curious person?                           31.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO7FKIYyD34w"
      },
      "source": [
        "The table above shows the rank for each questions with respect to the hobbies. The lower the score the more correlated the question is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0KUzp2DuraX",
        "outputId": "4b32fab2-7657-437c-dda1-999bc19e9040"
      },
      "source": [
        "# 24 questions as the features has the best result\n",
        "best_k_features = select_best_k_features(rfe_result, k=24)\n",
        "best_k_features # below is the list of top 24 questions "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender: ',\n",
              " 'What is your favorite color?',\n",
              " 'Are you a perfectionist?',\n",
              " 'Do you enjoy socializing with large groups of people?',\n",
              " 'Do you have lot of patience?',\n",
              " 'What do you worry more about the most?',\n",
              " 'Do you organize your schedule well?',\n",
              " 'Are you a trusting person?',\n",
              " 'Do you enjoy challenges?',\n",
              " 'Do you like to sit in front of a computer for long hours?',\n",
              " 'How creative of a person do you think you are?',\n",
              " 'How confident are you in your own abilities?',\n",
              " 'What boosts your confidence ? ',\n",
              " \"When you retire, you'd like to live...\",\n",
              " 'What is your favorite time of the day?',\n",
              " 'Do you enjoy making others happy?',\n",
              " 'How logical of a person do you think you are?',\n",
              " 'I prefer to spend my money on....',\n",
              " 'Choose a pet which you prefer to keep.',\n",
              " \"Can you understand others' perspectives and feelings?\",\n",
              " 'What is your learning style? (Pick one that benefit you the most)',\n",
              " 'How do you organize your thoughts? Please pick whichever is closest.',\n",
              " 'Would you prefer to engage your brain more than your body?',\n",
              " 'What is your current occupation?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMaEigoD52Sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "2ee57c48-0215-4aef-ea62-65be40386e95"
      },
      "source": [
        "# 24 questions as the features are trained and evaluated on all models\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Spiritual and Mental(27)</th>\n",
              "      <th>Games(26)</th>\n",
              "      <th>Sports and Outdoors(25)</th>\n",
              "      <th>Performing Arts(18)</th>\n",
              "      <th>Food and Drinks(10)</th>\n",
              "      <th>Arts and Craft(9)</th>\n",
              "      <th>Rejuvenation(7)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>62.295082</td>\n",
              "      <td>80.597015</td>\n",
              "      <td>71.186441</td>\n",
              "      <td>69.230769</td>\n",
              "      <td>45.161290</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Random_Forest</th>\n",
              "      <td>61.538462</td>\n",
              "      <td>75.362319</td>\n",
              "      <td>73.333333</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_MLP</th>\n",
              "      <td>60.937500</td>\n",
              "      <td>75.862069</td>\n",
              "      <td>77.192982</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>47.058824</td>\n",
              "      <td>31.578947</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Ridge</th>\n",
              "      <td>60.905350</td>\n",
              "      <td>79.365079</td>\n",
              "      <td>69.090909</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Extra_Trees</th>\n",
              "      <td>60.162602</td>\n",
              "      <td>79.411765</td>\n",
              "      <td>72.413793</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Random_Forest</th>\n",
              "      <td>59.677419</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>68.852459</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>46.666667</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Ridge</th>\n",
              "      <td>59.200000</td>\n",
              "      <td>74.626866</td>\n",
              "      <td>67.857143</td>\n",
              "      <td>67.924528</td>\n",
              "      <td>42.424242</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier_Chain_Decision_Tree</th>\n",
              "      <td>57.777778</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>68.493151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_MLP</th>\n",
              "      <td>57.031250</td>\n",
              "      <td>74.576271</td>\n",
              "      <td>64.150943</td>\n",
              "      <td>62.745098</td>\n",
              "      <td>47.058824</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>52.631579</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARAM_Neural_Network</th>\n",
              "      <td>56.179775</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>60.377358</td>\n",
              "      <td>57.692308</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_A</th>\n",
              "      <td>53.231939</td>\n",
              "      <td>77.966102</td>\n",
              "      <td>53.846154</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>43.902439</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multi-Label_KNN</th>\n",
              "      <td>53.231939</td>\n",
              "      <td>77.966102</td>\n",
              "      <td>53.846154</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>43.902439</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>22.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twin_SVM</th>\n",
              "      <td>52.849741</td>\n",
              "      <td>73.239437</td>\n",
              "      <td>72.463768</td>\n",
              "      <td>65.625000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>29.787234</td>\n",
              "      <td>35.897436</td>\n",
              "      <td>38.095238</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_kNN_B</th>\n",
              "      <td>25.190840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.714286</td>\n",
              "      <td>31.578947</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Overall  ... Collecting(4)\n",
              "Binary_Relevance_Extra_Trees    62.295082  ...      0.000000\n",
              "Classifier_Chain_Random_Forest  61.538462  ...      0.000000\n",
              "Classifier_Chain_MLP            60.937500  ...      0.000000\n",
              "Classifier_Chain_Ridge          60.905350  ...      0.000000\n",
              "Classifier_Chain_Extra_Trees    60.162602  ...      0.000000\n",
              "Binary_Relevance_Random_Forest  59.677419  ...      0.000000\n",
              "Binary_Relevance_Ridge          59.200000  ...      0.000000\n",
              "Binary_Relevance_Decision_Tree  57.777778  ...      0.000000\n",
              "Classifier_Chain_Decision_Tree  57.777778  ...      0.000000\n",
              "Binary_Relevance_MLP            57.031250  ...      0.000000\n",
              "ARAM_Neural_Network             56.179775  ...     20.000000\n",
              "Binary_Relevance_kNN_A          53.231939  ...     22.222222\n",
              "Multi-Label_KNN                 53.231939  ...     22.222222\n",
              "Twin_SVM                        52.849741  ...      8.000000\n",
              "Binary_Relevance_kNN_B          25.190840  ...     10.000000\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqOJDmN_GPAF"
      },
      "source": [
        "# Save and load the Best Model\n",
        "https://stackabuse.com/scikit-learn-save-and-restore-models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmzR7osSERcJ"
      },
      "source": [
        "Based on all the evaluation result above, the best model is Binary_Relevance_Extra_Trees with 8 questions as the features only with a score of 62.6% followed by the same model with 24 questions as the features only with a score of 62.29%. However, on average, all the other models with 8 questions as the features are not higher than the models with 24 questions as the features. Therefore, the model that trained on 24 questions as the features is more reliable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFUFfWFQtWgO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "9afb31e7-d7f8-4f13-b78c-2bd23dca2189"
      },
      "source": [
        "# 24 features\n",
        "# Q:Would you rather visit the future or the past?\t\n",
        "# Q:Are you a curious person?\t\n",
        "# these 2 questions above were not trained on\n",
        "display_evaluation_result(results, y, x_test, y_test, distribution_of_hobbies_train_test, f1_average = \"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Spiritual and Mental(27)</th>\n",
              "      <th>Games(26)</th>\n",
              "      <th>Sports and Outdoors(25)</th>\n",
              "      <th>Performing Arts(18)</th>\n",
              "      <th>Food and Drinks(10)</th>\n",
              "      <th>Arts and Craft(9)</th>\n",
              "      <th>Rejuvenation(7)</th>\n",
              "      <th>Collecting(4)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Binary_Relevance_Extra_Trees</th>\n",
              "      <td>62.295082</td>\n",
              "      <td>80.597015</td>\n",
              "      <td>71.186441</td>\n",
              "      <td>69.230769</td>\n",
              "      <td>45.16129</td>\n",
              "      <td>30.769231</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Overall  ... Collecting(4)\n",
              "Binary_Relevance_Extra_Trees  62.295082  ...           0.0\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EH62h-Xuodl",
        "outputId": "69fa88c8-ea5c-4746-e88d-77945eec4e44"
      },
      "source": [
        "print(\"The best hyperparameters for Binary_Relevance_Extra_Trees are:\")\n",
        "results[\"Binary_Relevance_Extra_Trees\"].best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best hyperparameters for Binary_Relevance_Extra_Trees are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__min_samples_leaf': 2,\n",
              " 'classifier__min_samples_split': 2,\n",
              " 'classifier__n_estimators': 90,\n",
              " 'classifier__n_jobs': -1,\n",
              " 'classifier__random_state': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g1lJ2e4wE7a"
      },
      "source": [
        "# save the model to disk\n",
        "pkl_filename = \"Binary_Relevance_Extra_Trees_model.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    # the model is stored in results dict\n",
        "    pickle.dump(results[\"Binary_Relevance_Extra_Trees\"], file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeeappD4wpwY"
      },
      "source": [
        "# load the model from disk\n",
        "pkl_filename = \"Binary_Relevance_Extra_Trees_model.pkl\"\n",
        "with open(pkl_filename, 'rb') as file:\n",
        "    model = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}